{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fully connected_match_laliga.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1T7ojSerzuoi",
        "colab_type": "code",
        "outputId": "76bfb507-ad47-4c5b-ce71-ae9d4f8f4158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        }
      },
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Setup python environment and change the current working directory\n",
        "######################################################################\n",
        "!pip3 install torch torchvision\n",
        "!pip3 install Pillow==4.0.0\n",
        "!pip3 install tensorboardX\n",
        "%mkdir -p /content/final_project\n",
        "%cd /content/final_project\n",
        "%mkdir ./output\n",
        "%mkdir ./data"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "  Using cached https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-6.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.2.post3 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mscikit-image 0.14.2 has requirement pillow>=4.3.0, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 6.0.0\n",
            "    Uninstalling Pillow-6.0.0:\n",
            "      Successfully uninstalled Pillow-6.0.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.9.0)\n",
            "/content/final_project\n",
            "mkdir: cannot create directory ‘./output’: File exists\n",
            "mkdir: cannot create directory ‘./data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dAu4eNhG08lf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Setting Constants"
      ]
    },
    {
      "metadata": {
        "id": "LCugAtvm0rOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook\n",
        "import torch\n",
        "import numpy as numpy\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xO3e1YhZQM4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv /content/train_Laliga_Complete_Dataset_All.csv /content/final_project/data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9d_pkUHSIOca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv /content/train_all.csv /content/final_project/data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mrLUq-3U1C8P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MatchDataset"
      ]
    },
    {
      "metadata": {
        "id": "OLOe_cJR1Gsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MatchDataset(Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        df = pd.read_csv(csv_path, index_col=0)\n",
        "\n",
        "        self.target_df = df.iloc[:, 25] # home_win = 0, away_win = 1, draw = 2\n",
        "        self.baseline_df = df.iloc[:, 26:620]\n",
        "    def __len__(self):\n",
        "        return len(self.baseline_df.index) - 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        baseline_input = torch.tensor(self.baseline_df.iloc[index, :], dtype=torch.float)\n",
        "        target = torch.tensor(self.target_df.iloc[index], dtype=torch.long)\n",
        "\n",
        "        output = {'baseline_input': baseline_input, 'target':target}\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LF69h8DIJfcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "b8c6843a-3465-49a7-e592-beefb97075a3"
      },
      "cell_type": "code",
      "source": [
        "train_dataset = MatchDataset('data/train_Laliga_Complete_Dataset_All.csv')\n",
        "#train_dataset = MatchDataset('data/train_all.csv')\n",
        "train_dataset.target_df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2       0\n",
              "4       2\n",
              "11      0\n",
              "14      2\n",
              "18      1\n",
              "20      0\n",
              "26      2\n",
              "27      0\n",
              "31      1\n",
              "39      1\n",
              "43      0\n",
              "44      0\n",
              "45      0\n",
              "47      0\n",
              "48      0\n",
              "49      0\n",
              "50      0\n",
              "55      0\n",
              "57      2\n",
              "58      1\n",
              "63      2\n",
              "65      0\n",
              "66      0\n",
              "70      1\n",
              "73      0\n",
              "74      2\n",
              "77      1\n",
              "79      0\n",
              "86      0\n",
              "87      0\n",
              "       ..\n",
              "2190    0\n",
              "2191    1\n",
              "2192    2\n",
              "2193    2\n",
              "2194    1\n",
              "2195    2\n",
              "2196    0\n",
              "2197    0\n",
              "2198    1\n",
              "2199    2\n",
              "2200    0\n",
              "2201    2\n",
              "2202    2\n",
              "2203    0\n",
              "2204    0\n",
              "2205    2\n",
              "2206    1\n",
              "2207    0\n",
              "2208    2\n",
              "2209    0\n",
              "2210    0\n",
              "2211    2\n",
              "2212    0\n",
              "2213    1\n",
              "2214    1\n",
              "2215    2\n",
              "2216    1\n",
              "2217    0\n",
              "2218    0\n",
              "2219    0\n",
              "Name: win, Length: 1799, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "5lfGCuPdLqcX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#validation_dataset = MatchDataset('data/test_all.csv')\n",
        "validation_dataset = MatchDataset('data/test_Laliga_Complete_Dataset_All.csv')\n",
        "validation_dataset.baseline_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KpbYJlTCPcQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# FULLY CONNECTED LAYER"
      ]
    },
    {
      "metadata": {
        "id": "awj5kx-ECQfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Fully_Connected(nn.Module):\n",
        "    def __init__(self, input_size1=297, input_size2=297, hidden_size1=2000, hidden_size2=2000, hidden_size3=4000, output_size=3):\n",
        "        super(Fully_Connected, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size1, hidden_size1)\n",
        "        self.fc2 = nn.Linear(input_size2, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size3, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = x[:, 0:297]\n",
        "        x2 = x[:, 297:594]\n",
        "        x1 = F.relu(self.fc1(x1))\n",
        "        x2 = F.relu(self.fc2(x2))\n",
        "        x_cat = torch.cat((x1, x2), 1)\n",
        "        x_cat = F.relu(self.fc3(x_cat))\n",
        "        y = F.softmax(x_cat, dim=1)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xOj-3CBhE7ul",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# FULLY CONNECTED LAYER TRAINER"
      ]
    },
    {
      "metadata": {
        "id": "iS6SUEpNgZU9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FullyConnectedTrainer:\n",
        "    def __init__(self, FullyConnected, train_dataloader, val_dataloader=None, lr=1e-3, \n",
        "                 with_cuda=True, cuda_device=None):\n",
        "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
        "        self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
        "#         self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
        "        self.model = Fully_Connected().to(self.device)\n",
        "        self.p_loss = nn.CrossEntropyLoss()\n",
        "        self.FullyConnected = FullyConnected\n",
        "        \n",
        "        if with_cuda and torch.cuda.device_count() > 1:\n",
        "            print(\"Using %d GPUS for Fully Connected\" % torch.cuda.device_count())\n",
        "            self.model = nn.DataParallel(self.model, device_ids=cuda_devices)\n",
        "\n",
        "        self.train_data = train_dataloader\n",
        "        self.val_data = val_dataloader\n",
        "\n",
        "        self.optimizer = torch.optim.SGD((self.model).parameters(), lr=lr, momentum=0.95)\n",
        "\n",
        "        self.losses = {'train_loss':[], 'validation_loss':[]}\n",
        "        self.accuracy = {'train_accuracy':[], 'validation_accuracy':[]}\n",
        "            \n",
        "\n",
        "    def train(self, epoch):\n",
        "        self.iteration(epoch, self.train_data)\n",
        "\n",
        "    def test(self, epoch):\n",
        "        self.iteration(epoch, self.val_data, False)\n",
        "\n",
        "    def iteration(self, epoch, data_loader, train=True):\n",
        "        \"\"\" Iteration process for one epoch. \n",
        "        \"\"\"\n",
        "        process = \"train\" if train else \"validation\"\n",
        "\n",
        "        data_iterator = tqdm_notebook(enumerate(data_loader),\n",
        "                              desc=\"EP %d %s\" % (epoch, process),\n",
        "                              total=len(data_loader),\n",
        "                              bar_format=\"{l_bar}{r_bar}\")\n",
        "\n",
        "        average_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        num_0 = 0\n",
        "        num_1 = 0\n",
        "        num_2 = 0\n",
        "        \n",
        "        for i, data in data_iterator:\n",
        "            data = {key: value.to(self.device) for key, value in data.items()}\n",
        "            output = self.model.forward(data['baseline_input'])\n",
        "            hit = output.argmax(dim=-1).eq(data[\"target\"]).sum().item()\n",
        "            miss = data[\"target\"].nelement() - hit\n",
        "            \n",
        "            loss = self.p_loss(output, data['target'])\n",
        "\n",
        "            if train:\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "            average_loss += loss.item()\n",
        "            correct += hit\n",
        "            total += data[\"target\"].nelement()\n",
        "            \n",
        "            # count \n",
        "            num_0 += output.argmax(dim=-1).eq(0).sum().item()\n",
        "            num_1 += output.argmax(dim=-1).eq(1).sum().item()\n",
        "            num_2 += output.argmax(dim=-1).eq(2).sum().item()\n",
        "\n",
        "            log_info = {\n",
        "                    \"epoch\": epoch, \n",
        "                    \"iteration\": i,\n",
        "                    \"total_loss\": average_loss / (i + 1),\n",
        "                    \"average_accuracy\": correct / total * 100,\n",
        "            }\n",
        "        \n",
        "        print('0:', num_0, ' | ', '1:', num_1, ' | ', '2:', num_2)\n",
        "        print('average_accuracy: ', log_info['average_accuracy'])\n",
        "        print('total_loss: ', log_info['total_loss'])\n",
        "\n",
        "        self.losses['{}_loss'.format(process)].append(log_info['total_loss'])\n",
        "        self.accuracy['{}_accuracy'.format(process)].append(log_info['average_accuracy'])\n",
        "\n",
        "    def save(self, epoch, filepath = \"output/trained.model\"):\n",
        "            if epoch % 10 == 0:\n",
        "                output_path = filepath + \".ep%d\" % epoch\n",
        "                torch.save(self.FullyConnected.cpu(), output_path)\n",
        "                self.FullyConnected.to(self.device)\n",
        "                print(\"EP:%d Model saved to:\" % epoch, output_path)\n",
        "                return output_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IeE5BRd7If_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ]
    },
    {
      "metadata": {
        "id": "EZBzfwXwIiDx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "\n",
        "def print_opts(opts):\n",
        "    \"\"\"Prints the values of arguments.\n",
        "    \"\"\"\n",
        "    print('=' * 80)\n",
        "    print('Opts'.center(80))\n",
        "    print('-' * 80)\n",
        "    for key in opts.__dict__:\n",
        "        print('{:>30}: {:<30}'.format(key, str(opts.__dict__[key])).center(80))\n",
        "    print('=' * 80)\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    # Load Data\n",
        "    print(\"=== Loading datasets ===\")\n",
        "    train_dataset = MatchDataset(args.train_path)\n",
        "    validation_dataset = MatchDataset(args.val_path)\n",
        "    train_dataloader = DataLoader(train_dataset,\n",
        "                                  batch_size=args.batch_size, num_workers=10)\n",
        "\n",
        "    val_dataloader = DataLoader(validation_dataset,\n",
        "                                     batch_size=args.batch_size, num_workers=10)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    # Build model\n",
        "    print(\"=== Building Model ===\")\n",
        "    baseline = Fully_Connected()\n",
        "\n",
        "    trainer = FullyConnectedTrainer(FullyConnected=baseline, \n",
        "                          train_dataloader=train_dataloader,\n",
        "                          val_dataloader=val_dataloader, \n",
        "                          lr=args.lr)\n",
        "\n",
        "    print(\"=== Start Training ===\")\n",
        "    for epoch in range(args.epochs):\n",
        "        print (\"epoch number: \" + str(epoch))\n",
        "        trainer.train(epoch)\n",
        "        trainer.save(epoch, args.output_path)\n",
        "\n",
        "        if val_dataloader is not None:\n",
        "            trainer.test(epoch)\n",
        "    \n",
        "    loss_df = pd.DataFrame.from_dict(trainer.losses)\n",
        "    accuracy_df = pd.DataFrame.from_dict(trainer.accuracy)\n",
        "    loss_df.plot(xticks=range(0, args.epochs, 5))\n",
        "    accuracy_df.plot(xticks=range(0, args.epochs,5))\n",
        "    \n",
        "    return baseline, trainer\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JN7zhn9yNxQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "MdkWvJ7WMjgD",
        "colab_type": "code",
        "outputId": "95372623-bc46-4407-9e47-300c896830ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2054
        }
      },
      "cell_type": "code",
      "source": [
        "args = AttrDict()\n",
        "default_config = {\n",
        "    \"train_path\": \"data/train_Laliga_Complete_Dataset_All.csv\",\n",
        "    \"val_path\": \"data/test_Laliga_Complete_Dataset_All.csv\",\n",
        "    \"batch_size\": 100,\n",
        "    \"epochs\": 100,\n",
        "    \"lr\": 0.001,\n",
        "    \"output_path\": 'output/exp1.model',\n",
        "}\n",
        "\n",
        "args.update(default_config)\n",
        "print_opts(args)\n",
        "baseline, trainer = train(args)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                                      Opts                                      \n",
            "--------------------------------------------------------------------------------\n",
            "                       train_path: data/train_Laliga_Complete_Dataset_All.csv   \n",
            "                         val_path: data/test_Laliga_Complete_Dataset_All.csv    \n",
            "                             batch_size: 100                                    \n",
            "                                 epochs: 100                                    \n",
            "                                     lr: 0.001                                  \n",
            "                            output_path: output/exp1.model                      \n",
            "================================================================================\n",
            "=== Loading datasets ===\n",
            "=== Building Model ===\n",
            "=== Start Training ===\n",
            "epoch number: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de8573a2ab564c8c9361e5cce2105957",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='EP 0 train', max=18, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0: 0  |  1: 94  |  2: 1704\n",
            "average_accuracy:  23.02558398220245\n",
            "total_loss:  1.320296459727817\n",
            "EP:0 Model saved to: output/exp1.model.ep0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Fully_Connected. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c17dc3ba5774e128aca4888054e1065",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='EP 0 validation', max=5, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0: 0  |  1: 0  |  2: 447\n",
            "average_accuracy:  24.832214765100673\n",
            "total_loss:  1.3023810625076293\n",
            "epoch number: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f6d8faf2e5e4263b00d403c2501f152",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='EP 1 train', max=18, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0: 0  |  1: 0  |  2: 1798\n",
            "average_accuracy:  23.136818687430477\n",
            "total_loss:  1.3200389477941725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1afc58fcbf964b28bbb406dcb1524fa7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='EP 1 validation', max=5, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0: 0  |  1: 0  |  2: 447\n",
            "average_accuracy:  24.832214765100673\n",
            "total_loss:  1.3023810625076293\n",
            "epoch number: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdbbefeed1e348c2be9a45807d9c4b24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='EP 2 train', max=18, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0: 0  |  1: 0  |  2: 1798\n",
            "average_accuracy:  23.136818687430477\n",
            "total_loss:  1.3200389477941725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d817a62f9ca44ecbbfa7d613cece268",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='EP 2 validation', max=5, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0: 0  |  1: 0  |  2: 447\n",
            "average_accuracy:  24.832214765100673\n",
            "total_loss:  1.3023810625076293\n",
            "epoch number: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdac0ce397964feeb10ac4451bb95a0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='EP 3 train', max=18, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-98cd2138b059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-90-7f001cdaa2fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch number: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-4e0edb297612>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-4e0edb297612>\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch, data_loader, train)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mnum_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'baseline_input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}